{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # matrix operations\nimport pandas as pd # data processing, CSV file processing\n\n# Imports Keras for Deep Learning Model\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten,MaxPooling2D, LeakyReLU\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# import image processor and data visualization tool\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom glob import glob\nimport random\n\n# trainning data files are in the \"../input/asl_alphabet_train/asl_alphabet_train/\" directory.\n# test data files are in the \"../input/asl_alphabet_train/asl_alphabet_train/\" directory.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def plot_samples(letter):\n    print(\"check images for letter \" + letter)\n    base_path = '../input/asl_alphabet_train/asl_alphabet_train/'\n    img_path = base_path + letter + '/**'\n    all_contents = glob(img_path)\n    \n    plt.figure(figsize = (16,16))\n    imgs = random.sample(all_contents, 3)\n    \n    print(\"image shape: \" + str(cv2.imread(imgs[0]).shape))\n    \n    plt.subplot(1,3,1)\n    plt.imshow(cv2.imread(imgs[0]))\n    plt.subplot(1,3,2)\n    plt.imshow(cv2.imread(imgs[1]))\n    plt.subplot(1,3,3)\n    plt.imshow(cv2.imread(imgs[2]))\n    return\n\nplot_samples('A')\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Augumentation"},{"metadata":{"_uuid":"12619700f7f1d53c76dbf08aacd29007d70dddac","trusted":false},"cell_type":"code","source":"data_dir = \"../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/\"\ntarget_size = (64, 64)\ntarget_dims = (64, 64, 3)\nnum_classes = 29\n\ndata_augmentor = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True, validation_split=0.3)\ntrain_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=64, shuffle=True, subset=\"training\")\nval_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=64, subset=\"validation\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create CNN Model"},{"metadata":{"_uuid":"aceabcdf0c099e7971607deabaea1abcf67ab035","trusted":false},"cell_type":"code","source":"def create_model():\n    my_model = Sequential()\n    my_model.add(Conv2D(32, kernel_size=2, strides=1, input_shape=target_dims, padding=\"SAME\"))\n    my_model.add(LeakyReLU())\n    my_model.add(MaxPooling2D(pool_size=(2,2)))\n    my_model.add(Dropout(0.5))\n    my_model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"SAME\"))\n    my_model.add(LeakyReLU())\n    my_model.add(MaxPooling2D(pool_size=(3,3)))\n    my_model.add(Dropout(0.5))\n    my_model.add(Conv2D(128, kernel_size=4, strides=1, padding=\"SAME\"))\n    my_model.add(LeakyReLU())\n    my_model.add(MaxPooling2D(pool_size=(4,4)))\n    my_model.add(Dropout(0.5))\n    my_model.add(Conv2D(256, kernel_size=4, strides=1, padding=\"SAME\"))\n    my_model.add(LeakyReLU())\n    my_model.add(MaxPooling2D(pool_size=(2,2)))\n    my_model.add(Flatten())\n    my_model.add(Dropout(0.5))\n    my_model.add(Dense(512, activation='relu'))\n    my_model.add(Dense(num_classes, activation='softmax'))\n    my_model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n    return my_model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34c289f40bf1bec8911e7fb70b299291f1d4f1cd","trusted":false},"cell_type":"code","source":"cur_model = create_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train CNN Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"cur_model.fit_generator(train_generator, epochs=30, validation_data=val_generator)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d2eaaaa6f821540b842b3b0c060b1c185f0fa8a","trusted":false},"cell_type":"code","source":"cur_model.save('cnn_model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"img = cv2.imread('../input/test-img-sets/test4.jpeg')\nplt.imshow(img)\nplot_samples('A')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"375d126fe9ee4b61520e26ef2d6d5b6ec308fea4","trusted":false},"cell_type":"code","source":"test_img = cv2.resize(img, (64,64), interpolation = cv2.INTER_CUBIC)\nplt.imshow(test_img)\ntest_img = np.array([test_img])\ntest_img.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d04a9a6dd77a615618cc299299c711d3b285af3a","trusted":false},"cell_type":"code","source":"test_label = cur_model.predict_classes(test_img)\n\n# check the probability of predicted class\nprint(cur_model.predict(test_img)[0][[cur_model.predict_classes(test_img)[0]]])\n\nfor character, label in train_generator.class_indices.items():\n    if label == test_label:\n        print('cnn_model result: ' + character)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Try SVM and other Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import SVM packages from sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import svm, metrics, datasets\nfrom sklearn.utils import Bunch\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.externals import joblib\n\nimport os\nimport h5py","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Featurizers\n\nConcatenates 3 global features into a single global feature and then saves it in a HDF5 file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# featurizer1: Image Moments\ndef f1_image_moments(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n    return feature\n\n# featurizer2: Color Histogram\ndef f2_color_histogram(image, mask=None):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist  = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n    cv2.normalize(hist, hist)\n    return hist.flatten()\n\n# featurizer3: Histogram of Oriented Gradients (be careful: this featurizer will generate a very large size data)\ndef f3_hog(image):\n    hog = cv2.HOGDescriptor()\n    h = hog.compute(image)\n    return h.flatten()","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the training dataset\ntrain_path = '../input/asl_alphabet_train/asl_alphabet_train/'\ntrain_labels = os.listdir(train_path)\n\n# get the test dataset\ntest_path = '../input/asl_alphabet_test/asl_alphabet_test/'\n\n# sort the training/test labels\ntrain_labels.sort()\ntest_labels = train_labels\nprint('train labels: ' + str(train_labels))\nprint('test labels: ' + str(test_labels))\n\n# empty lists to hold feature vectors and labels\nglobal_features = []\nlabels = []\n\n# take top 300 training data for now: (TO-DO: find a way to fit all trainning data in memeory)\ntrain_size = 300\n\n# loop over the training dataset\nfor training_name in train_labels:\n    \n    # get the current training label\n    dir = os.path.join(train_path, training_name)\n    current_label = training_name\n    number_of_images = len([name for name in dir])\n    \n    k = 1\n    \n    for file in glob(dir + '/*.jpg'):\n\n        image = cv2.imread(file)\n        \n        # Global Features extraction\n        f1v_image_moments = f1_image_moments(image)\n        f2v_color_histogram  = f2_color_histogram(image)\n        \n        # comment out the HOG featurizer for smaller matrix size (TO-DO: find a way to reduce HOG feature size)\n        #f3v_hog = f3_hog(image)\n\n        # Concatenate feature values\n        #global_feature = np.hstack([f1v_image_moments, f2v_color_histogram,  f3v_hog])\n        global_feature = np.hstack([f1v_image_moments, f2v_color_histogram])\n\n        # update the list of labels and feature vectors\n        labels.append(current_label)\n        global_features.append(global_feature)\n        \n        k+=1\n        \n        if k >= train_size:\n            break\n            \n\n    print(\"processed trainning folder:\" + current_label)","execution_count":14,"outputs":[{"output_type":"stream","text":"train labels: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\ntest labels: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\nprocessed trainning folder:A\nprocessed trainning folder:B\nprocessed trainning folder:C\nprocessed trainning folder:D\nprocessed trainning folder:E\nprocessed trainning folder:F\nprocessed trainning folder:G\nprocessed trainning folder:H\nprocessed trainning folder:I\nprocessed trainning folder:J\nprocessed trainning folder:K\nprocessed trainning folder:L\nprocessed trainning folder:M\nprocessed trainning folder:N\nprocessed trainning folder:O\nprocessed trainning folder:P\nprocessed trainning folder:Q\nprocessed trainning folder:R\nprocessed trainning folder:S\nprocessed trainning folder:T\nprocessed trainning folder:U\nprocessed trainning folder:V\nprocessed trainning folder:W\nprocessed trainning folder:X\nprocessed trainning folder:Y\nprocessed trainning folder:Z\nprocessed trainning folder:del\nprocessed trainning folder:nothing\nprocessed trainning folder:space\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_global_features = []\ntest_labels = []\n\nfor file in glob(test_path + '/*.jpg'):\n    image = cv2.imread(file)\n    \n    current_label = file[str(file).rfind('/') + 1:str(file).rfind('_test')]\n\n    # Global Features extraction\n    f1v_image_moments = f1_image_moments(image)\n    f2v_color_histogram  = f2_color_histogram(image)\n    f3v_hog = f3_hog(image)\n    \n    # Concatenate feature values\n    global_feature = np.hstack([f1v_image_moments, f2v_color_histogram,  f3v_hog])\n    \n    # update the list of labels and feature vectors\n    test_labels.append(current_label)\n    test_global_features.append(global_feature)\n    print(\"processed test folder:\" + current_label)","execution_count":15,"outputs":[{"output_type":"stream","text":"processed test folder:X\nprocessed test folder:V\nprocessed test folder:U\nprocessed test folder:space\nprocessed test folder:R\nprocessed test folder:B\nprocessed test folder:W\nprocessed test folder:J\nprocessed test folder:Z\nprocessed test folder:A\nprocessed test folder:N\nprocessed test folder:P\nprocessed test folder:M\nprocessed test folder:T\nprocessed test folder:E\nprocessed test folder:Q\nprocessed test folder:G\nprocessed test folder:D\nprocessed test folder:Y\nprocessed test folder:F\nprocessed test folder:O\nprocessed test folder:L\nprocessed test folder:S\nprocessed test folder:nothing\nprocessed test folder:C\nprocessed test folder:K\nprocessed test folder:I\nprocessed test folder:H\n","name":"stdout"}]},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# get feature vector size\nprint(\"feature vector size:\" + str(np.array(global_features).shape))\n\n# get training label size\nprint(\" training Labels: \" +  str(np.array(labels).shape))\n\n# encode the target labels\ntargetNames = np.unique(labels)\nle = LabelEncoder()\ntarget = le.fit_transform(labels)\n\n# normalize the feature vector\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaled_features = scaler.fit_transform(global_features)\n\n# save the feature vector using hdf5\ndirName = '../output'\ntry:\n    # Create target Directory\n    os.mkdir(dirName)\n    print(\"Directory \" , dirName ,  \" Created \") \nexcept FileExistsError:\n    print(\"Directory \" , dirName ,  \" already exists\")\n\n    \nsvm_data_exists = os.path.isfile('../output/svm_data.h5')\nif svm_data_exists:\n    os.remove('../output/svm_data.h5')\n\nsvm_labels_exists = os.path.isfile('../output/svm_labels.h5')\nif svm_labels_exists:\n    os.remove('../output/svm_labels.h5')\n    \ncreate_h5f_data = open('../output/svm_data.h5', \"x\")\nh5f_data = h5py.File('../output/svm_data.h5', 'w')\nh5f_data.create_dataset('svm_data_1', data=np.array(rescaled_features))\n\ncreate_h5f_label = open(\"../output/svm_labels.h5\", \"x\")\nh5f_label = h5py.File('../output/svm_labels.h5', 'w')\nh5f_label.create_dataset('svm_data_1', data=np.array(target))\n\nh5f_data.close()\nh5f_label.close()","execution_count":16,"outputs":[{"output_type":"stream","text":"feature vector size:(2871, 519)\n training Labels: (2871,)\nDirectory  ../output  already exists\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Create Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create all the machine learning models\nmodels = []\nmodels.append(('LR', LogisticRegression(random_state=9)))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier(random_state=9)))\nmodels.append(('RF', RandomForestClassifier(n_estimators=100, random_state=9)))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(random_state=9)))\n\ntrain_data = np.array(global_features)\ntest_data = np.array(test_global_features)\ntrain_labels = np.array(labels)\ntest_labels = np.array(test_labels)\n\n# check the shape of train/test dataset\nprint(\"Train data: \" + str(train_data.shape))\nprint(\"Test data: \" + str(test_data.shape))\nprint(\"Train labels: \" + str(train_labels.shape))\nprint(\"Test labels: \" + str(test_labels.shape))","execution_count":17,"outputs":[{"output_type":"stream","text":"Train data: (2871, 519)\nTest data: (28, 680919)\nTrain labels: (2871,)\nTest labels: (28,)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Trainning Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter all the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# variables to hold the results and names\nresults = []\nnames = []\n\n# K-fold cross validation take k = 8\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=7)\n    cv_results = cross_val_score(model, train_data, train_labels, cv=kfold, scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n# boxplot algorithm comparison\nfig = pyplot.figure()\nfig.suptitle('Model comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\npyplot.show()","execution_count":null,"outputs":[{"output_type":"stream","text":"LR: 0.030662 (0.037971)\nLDA: 0.144234 (0.050673)\nKNN: 0.126822 (0.076795)\nCART: 0.113231 (0.056548)\nRF: 0.140067 (0.081908)\nNB: 0.122252 (0.045079)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### *all other machine learning models do not have same performance as CNN model at this stage (TO-DO: add local featurizers for SVM and investage more possible global featurizers)*"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}